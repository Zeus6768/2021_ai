{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85262529",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron with MNIST handwritten digits classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8eedf",
   "metadata": {},
   "source": [
    "## 1. Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315ebfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bac6b",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9880ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.10.0  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5590af",
   "metadata": {},
   "source": [
    "## 3. MNIST 데이터 다운로드 (Train data와 Test data 분리하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00908077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.9%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "85.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n",
      "112.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17579718",
   "metadata": {},
   "source": [
    "## 4. 첫번째 batch 데이터의 크기와 타입을 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2818b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ee4fa",
   "metadata": {},
   "source": [
    "# Loss 구하기 \n",
    "   forward propagation을 계산하는 함수 구현하기\n",
    "   \n",
    "   1) input layer (입력층), hidden layer (은닉층), output layer (출력층) 으로 이루어진 모델을 이용\n",
    "\n",
    "   2) 하나의 hidden layer (은닉층)만 이용 - 은닉층의 개수는 100개로 하세요\n",
    "\n",
    "   3) 모든 것은 tensor 계산으로만 할 것!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfc2da",
   "metadata": {},
   "source": [
    "## ReLU, one_hot_encoding, softmax, cross_entropy 구하기\n",
    "\n",
    "아래 코드는 각 함수가 맞는지 확인하기 위해서 만든 임의의 값입니다. \n",
    "각 함수가 작동을 잘하는지 확인해 보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80f6bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.tensor([[1,-2,-4, 2, 5, 6, -3, -5, 0, 2],[2, -3, 4, 3, -1, -4, 3, 5, 2, -3]])\n",
    "true_label = torch.tensor([5,7])\n",
    "false_label = torch.tensor([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e322d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_func(outputs):\n",
    "    zero_tensor = torch.zeros(outputs.shape)\n",
    "    final_outputs = torch.maximum(outputs, zero_tensor)\n",
    "\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2f287",
   "metadata": {},
   "source": [
    "ReLU 함수가 맞는지 test_data를 이용하여 맞추어 보자. 아래 함수의 결과는 어떻게 예상되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe43970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 2., 5., 6., 0., 0., 0., 2.],\n",
       "        [2., 0., 4., 3., 0., 0., 3., 5., 2., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU_func(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a8e3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label):\n",
    "    \n",
    "    one_hot_outputs = torch.eye(10)[label]\n",
    "    \n",
    "    return one_hot_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd57e3",
   "metadata": {},
   "source": [
    "one_hot_encoding 함수가 맞는지 true_label, false_label을 이용하여 맞추어 보자. 아래 함수 결과는 어떻게 예상되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e73e407c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 9.9910e-01,\n",
      "         1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04],\n",
      "        [1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04, 1.0000e-04,\n",
      "         1.0000e-04, 9.9910e-01, 1.0000e-04, 1.0000e-04]])\n"
     ]
    }
   ],
   "source": [
    "# 검증을 위해 아래 4줄을 사용하면 됩니다. \n",
    "tl = one_hot_encoding(true_label)\n",
    "print(tl)\n",
    "fl = one_hot_encoding(false_label)\n",
    "print(fl)\n",
    "\n",
    "# 나중을 위해서 사용될 코드 입니다. \n",
    "close_tl = tl.clone()\n",
    "close_tl[[0,1],true_label] -= 0.001\n",
    "close_tl[false_label] += 0.0001\n",
    "print(close_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23f07c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(outputs):\n",
    "    \n",
    "    numerator = torch.exp(outputs - torch.max(outputs))\n",
    "    denominator = torch.sum(numerator, axis=1).view(-1,1)\n",
    "    softmax = numerator/denominator\n",
    "    \n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36037c34",
   "metadata": {},
   "source": [
    "softmax 함수가 맞는지 test_data를 이용하여 맞추어 보자. 아래 함수의 결과는 어떻게 예상되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "361e5708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7643e-03, 2.3720e-04, 3.2102e-05, 1.2951e-02, 2.6012e-01, 7.0709e-01,\n",
      "         8.7262e-05, 1.1810e-05, 1.7527e-03, 1.2951e-02],\n",
      "        [2.8590e-02, 1.9264e-04, 2.1126e-01, 7.7716e-02, 1.4234e-03, 7.0868e-05,\n",
      "         7.7716e-02, 5.7425e-01, 2.8590e-02, 1.9264e-04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = softmax(test_data)\n",
    "print(a)\n",
    "torch.sum(a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9c3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(outputs, labels):\n",
    "    return -torch.sum(labels * torch.log(outputs), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff4cae",
   "metadata": {},
   "source": [
    "cross_entropy 함수가 맞는지 test_data를 이용하여 맞추어 보자. 아래 함수의 결과는 어떻게 예상되는가? tl, fl, close_tl을 이용하여 각각의 cross entropy를 구하고 그 값이 맞는지 확인하세요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9998c30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0009, 0.0009])\n",
      "tensor([9.2103, 9.2103])\n",
      "tensor([0.3466, 0.5547])\n",
      "tensor([8.3466, 3.5547])\n"
     ]
    }
   ],
   "source": [
    "ideal_result = cross_entropy(close_tl, tl)\n",
    "non_ideal_result = cross_entropy(close_tl,fl)\n",
    "\n",
    "print(ideal_result)\n",
    "print(non_ideal_result)\n",
    "\n",
    "true_result = cross_entropy(a,tl)\n",
    "false_result = cross_entropy(a,fl)\n",
    "\n",
    "print(true_result)\n",
    "print(false_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b53388",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11604b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(train_loader):\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        # 이미지와 label를 1개로 만듬\n",
    "        image = image[0]\n",
    "        label = label[0]\n",
    "        \n",
    "        image = image.view(-1, 28 * 28)\n",
    "        print(image.size())\n",
    "        \n",
    "        # Weight(가중치)를 초기화 (torch rand 함수 이용, 도중에 빼기 0.5를 하여 함수값이 -0.5~0.5 사이로 만드세요)\n",
    "        W_ih = torch.rand(28 * 28, 100) - 0.5\n",
    "        \n",
    "        W_ho = torch.rand(100, 10) - 0.5 # ???\n",
    "        \n",
    "        # Forward propagration 계산하기.\n",
    "        \n",
    "        # 첫번째 Layer의 값\n",
    "        outputs = torch.dot(image, W_ih)  # 위 W_ih, image를 이용하여 1번째 hidden Layer의 값을 구하세요.\n",
    "        print(outputs.size())\n",
    "        # 결과 값(outputs)을 ReLU 함수에 적용하기\n",
    "        outputs = ReLu(outputs)\n",
    "        \n",
    "        # 출력 layer 계산 하기\n",
    "        outputs = W_ho * outputs\n",
    "        \n",
    "        # softmax 하기\n",
    "        softmaxed_outputs = softmax(outputs)\n",
    "    \n",
    "        \n",
    "             \n",
    "        # label 값을 one_hot 형태로 변환하기\n",
    "        expected_outputs = one_hot_encoding(label)\n",
    "        \n",
    "        #loss 값 구하기\n",
    "        loss = cross_entropy(softmaxed_outputs, expected_outputs)\n",
    "        print(loss)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d73d05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n",
      "torch.Size([784, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (784) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20560/189201142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 결과물이 맞다면 아래와 같은 값이 나오게 됩니다. 단, 2번째 줄의 값은 변동 가능합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20560/4190522234.py\u001b[0m in \u001b[0;36mforward_pass\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# 첫번째 Layer의 값\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW_ih\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage\u001b[0m  \u001b[1;31m# 위 W_ih, image를 이용하여 1번째 hidden Layer의 값을 구하세요.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# 결과 값(outputs)을 ReLU 함수에 적용하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (784) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "forward_pass(train_loader) # 결과물이 맞다면 아래와 같은 값이 나오게 됩니다. 단, 2번째 줄의 값은 변동 가능합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2 python3.7",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
